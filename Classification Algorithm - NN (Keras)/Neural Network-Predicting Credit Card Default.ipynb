{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('default_of_credit_card_clients.xls', index_col=\"ID\", skiprows=[0])\n",
    "\n",
    "print(a)\n",
    "\n",
    "#print(df.head())\n",
    "#print(df.describe())\n",
    "#print(df.info())\n",
    "\n",
    "# One Hot-Coding for categorical features : binary features take values of 1 or 0\n",
    "# - Scikit-learn might assume these are numerical features\n",
    "# - can't use labels because Scikit-learn only accepts numbers\n",
    "\n",
    "# obtain the one hot encoding of columns 'SEX', 'EDUCATION', 'MARRIAGE'\n",
    "# The base values are: female, other_education, other_marital_status\n",
    "df['male'] = (df['SEX'] == 1).astype('int')\n",
    "df.drop('SEX', axis=1, inplace=True)\n",
    "\n",
    "df['grad_school'] = (df['EDUCATION'] == 1).astype('int')\n",
    "df['university'] = (df['EDUCATION'] == 2).astype('int')\n",
    "df['high_school'] = (df['EDUCATION'] == 3).astype('int')\n",
    "df.drop('EDUCATION', axis=1, inplace=True)\n",
    "\n",
    "df['married'] = (df['MARRIAGE'] == 1).astype('int')\n",
    "df['single'] = (df['MARRIAGE'] == 2).astype('int')\n",
    "df.drop('MARRIAGE', axis=1, inplace=True)\n",
    "\n",
    "# From the documentation, we can infer that PAY_n features represent not delayed if it is <= 0\n",
    "pay_n_features = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for col in pay_n_features:\n",
    "    hist = df[col].hist(bins=10)\n",
    "    print(\"Plotting for column {}\".format(col))\n",
    "    plt.show()\n",
    "    \n",
    "# modify all values of PAY_n features which are < 0 to 0\n",
    "for pay_n in pay_n_features:\n",
    "    df.loc[df[pay_n] <= 0, pay_n] = 0\n",
    "\n",
    "df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "    \n",
    "pd.options.display.max_columns = None\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling to get more accurate representation and better learning performance\n",
    "'''\n",
    "Most machine learning algorithms take into account only the magnitude of the measurements, not the units of those measurements.\n",
    "The feature with a very high magnitude (number) may affect the prediction a lot more than an equally important feature.\n",
    "e.g. the AGE (within certain fixed range) and the PAY_AMTn (monetary) features have very different ranges of values\n",
    "\n",
    "RobustScaler:\n",
    "The Robust Scaler uses statistics that are robust to outliers.\n",
    "This usage of interquartiles means that they focus on the parts where the bulk of the data is.\n",
    "This makes them very suitable for working with outliers.\n",
    "Notice that after Robust scaling, the distributions are brought into the same scale and overlap, but the outliers remain outside of bulk of the new distributions.\n",
    "'''\n",
    "# plot the distribution of all data\n",
    "for col in df.columns:\n",
    "    hist = df[col].hist(bins=10)\n",
    "    print(\"Plotting for column {}\".format(col))\n",
    "    plt.show()\n",
    "\n",
    "x = df.drop('default', axis=1)\n",
    "rb_scaler = RobustScaler()\n",
    "x = rb_scaler.fit_transform(x)# rescale all the features to a same range\n",
    "y = df['default']\n",
    "# stratify parameter makes data split in a stratified fashion meaning the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_matrix(CM, labels=['pay', 'default']):\n",
    "    df = pd.DataFrame(data = CM, index=labels, columns=labels)\n",
    "    df.index.name = 'TRUE'\n",
    "    df.columns.name = 'PREDICTION'\n",
    "    df.loc['Total'] = df.sum()\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataframe to store the evaluation metrics\n",
    "metrics = pd.DataFrame(\n",
    "    index=['accuracy', 'precision', 'recall'],\n",
    "    columns=['NULL', 'LogisticReg', 'DecisionTree', 'NaiveBayes', 'NeuralNet']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this application\n",
    "\n",
    "1. Accuracy: Overall how often the model predicts correctly defaulters and non-defaulters?\n",
    "2. Precision: When the model predicts defaults: how often is correct?\n",
    "3. Recall: The proportion of actual defaulters that the model will correctly predict?\n",
    "\n",
    "### Which metric to use?\n",
    "1. False positive: A person who will pay predicted as defaulter\n",
    "2. False negative: A person who will default predicted as payer\n",
    "\n",
    "#### False negatives are worse => look for better recall\n",
    "\n",
    "## The Null model: always predict the most common category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark or base for how good the model must be performed to beat the Null model\n",
    "# predict the most common category which is 'pay'\n",
    "y_predicted = np.repeat(y_train.value_counts().idxmax(), y_test.size)\n",
    "metrics.loc['accuracy', 'NULL'] = accuracy_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['precision', 'NULL'] = precision_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['recall', 'NULL'] = recall_score(y_pred=y_predicted, y_true=y_test)\n",
    "\n",
    "# construct the confusion matrix\n",
    "CM = confusion_matrix(y_pred=y_predicted, y_true=y_test)\n",
    "c_matrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>1. Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create an instance of the model\n",
    "log_reg = LogisticRegression(n_jobs=-1, random_state=15)\n",
    "\n",
    "# train the model using the training data\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# evaluate the model performance\n",
    "y_predicted = log_reg.predict(x_test)\n",
    "metrics.loc['accuracy', 'LogisticReg'] = accuracy_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['precision', 'LogisticReg'] = precision_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['recall', 'LogisticReg'] = recall_score(y_pred=y_predicted, y_true=y_test)\n",
    "\n",
    "# construct the confusion matrix\n",
    "CM = confusion_matrix(y_pred=y_predicted, y_true=y_test)\n",
    "c_matrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>2. Decision Tree Classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model class\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create an instance of the model\n",
    "'''\n",
    "min_samples_split => minimum number of samples required to split an internal node\n",
    "min_samples_leaf => minimum number of samples required to be at a leaf node\n",
    "'''\n",
    "dec_tree = DecisionTreeClassifier(min_samples_split=30, min_samples_leaf=10, random_state=10)\n",
    "\n",
    "# train the model using the training data\n",
    "dec_tree.fit(x_train, y_train)\n",
    "\n",
    "# evaluate the model performance\n",
    "y_predicted = dec_tree.predict(x_test)\n",
    "metrics.loc['accuracy', 'DecisionTree'] = accuracy_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['precision', 'DecisionTree'] = precision_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['recall', 'DecisionTree'] = recall_score(y_pred=y_predicted, y_true=y_test)\n",
    "\n",
    "# construct the confusion matrix\n",
    "CM = confusion_matrix(y_pred=y_predicted, y_true=y_test)\n",
    "c_matrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>3. Naive Bayes Classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model class\n",
    "from sklearn.naive_bayes import GaussianNB# for features with continuous values\n",
    "\n",
    "# create an instance of the model\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# train the model using the training data\n",
    "nb_classifier.fit(x_train, y_train)\n",
    "\n",
    "# evaluate the model performance\n",
    "y_predicted = nb_classifier.predict(x_test)\n",
    "metrics.loc['accuracy', 'NaiveBayes'] = accuracy_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['precision', 'NaiveBayes'] = precision_score(y_pred=y_predicted, y_true=y_test)\n",
    "metrics.loc['recall', 'NaiveBayes'] = recall_score(y_pred=y_predicted, y_true=y_test)\n",
    "\n",
    "# construct the confusion matrix\n",
    "CM = confusion_matrix(y_pred=y_predicted, y_true=y_test)\n",
    "c_matrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>4. Feed Forward Deep Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Sequential Model (Using GridSearchCV)\n",
    "To use Keras model in Scikit Learn, we need to use the KerasClassifier or KerasRegressor classes. These two classes accept a function which creates and returns a Keras model.\n",
    "1. Tuning batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.constraints import unit_norm\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def cc_default_classifier():\n",
    "    input_dim = x_train.shape[1]\n",
    "\n",
    "    # Weight constraints provide an approach to reduce the overfitting of a deep learning neural network model on the training data and improve the performance of the model on new data\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(input_dim,), activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1,  activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=cc_default_classifier)\n",
    "\n",
    "batch_sizes = [24, 32]\n",
    "epochs = [30, 50]\n",
    "params = {\n",
    "    'batch_size': batch_sizes,\n",
    "    'epochs': epochs,\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, params, verbose=2, cv=3)\n",
    "clf.fit(np.array(x_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best score and best parameters\n",
    "print(\"Best mean test score and best parameters:\")\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "print()\n",
    "\n",
    "# Loop through and display each pair of mean test score and parameter\n",
    "print(\"List of Mean test scores and respective parameters:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "parameters = clf.cv_results_['params']\n",
    "for mean, parameter in zip(means, parameters):\n",
    "    print(mean, parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tuning optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import unit_norm\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def cc_default_classifier(optimizer):\n",
    "    input_dim = x_train.shape[1]\n",
    "\n",
    "    # Weight constraints provide an approach to reduce the overfitting of a deep learning neural network model on the training data and improve the performance of the model on new data\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(input_dim,), activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation='relu', kernel_constraint=unit_norm()))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1,  activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=cc_default_classifier, epochs=50, batch_size=24)\n",
    "\n",
    "params = {'optimizer':['SGD', 'Adagrad', 'Adadelta', 'Adam']}\n",
    "\n",
    "clf = GridSearchCV(model, params, verbose=2, cv=3)\n",
    "clf.fit(np.array(x_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best score and best parameters\n",
    "print(\"Best mean test score and best parameters:\")\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "print()\n",
    "\n",
    "# Loop through and display each pair of mean test score and parameter\n",
    "print(\"List of Mean test scores and respective parameters:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "parameters = clf.cv_results_['params']\n",
    "for mean, parameter in zip(means, parameters):\n",
    "    print(mean, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.constraints import unit_norm\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "# Weight constraints provide an approach to reduce the overfitting of a deep learning neural network model on the training data and improve the performance of the model on new data\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(input_dim,), activation='relu', kernel_constraint=unit_norm()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_constraint=unit_norm()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu', kernel_constraint=unit_norm()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu', kernel_constraint=unit_norm()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,  activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='Adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class BatchLogger(Callback):\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self.log_values = {}\n",
    "        for k in self.params['metrics']:\n",
    "            self.log_values[k] = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.log_values[k].append(logs[k])\n",
    "    \n",
    "    def get_values(self, metric_name, window):\n",
    "        d =  pd.Series(self.log_values[metric_name])\n",
    "        return d.rolling(window,center=False).mean()\n",
    "\n",
    "bl = BatchLogger()\n",
    "\n",
    "history = model.fit(np.array(x_train), np.array(y_train),\n",
    "              batch_size=24, epochs=50, verbose=1, callbacks=[bl],\n",
    "              validation_split=0.2)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot history\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, log_loss, accuracy_score, confusion_matrix\n",
    "\n",
    "def plot_cm(ax, y_true, y_pred, classes, title, th=0.5, cmap=plt.cm.Blues):\n",
    "    y_pred_labels = (y_pred>th).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred_labels)\n",
    "    \n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "\n",
    "def plot_auc(ax, y_train, y_train_pred, y_test, y_test_pred, th=0.5):\n",
    "\n",
    "    y_train_pred_labels = (y_train_pred>th).astype(int)\n",
    "    y_test_pred_labels  = (y_test_pred>th).astype(int)\n",
    "\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train,y_train_pred)\n",
    "    roc_auc_train = auc(fpr_train, tpr_train)\n",
    "    acc_train = accuracy_score(y_train, y_train_pred_labels)\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test,y_test_pred)\n",
    "    roc_auc_test = auc(fpr_test, tpr_test)\n",
    "    acc_test = accuracy_score(y_test, y_test_pred_labels)\n",
    "\n",
    "    ax.plot(fpr_train, tpr_train)\n",
    "    ax.plot(fpr_test, tpr_test)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC curve')\n",
    "    \n",
    "    train_text = 'train acc = {:.3f}, auc = {:.2f}'.format(acc_train, roc_auc_train)\n",
    "    test_text = 'test acc = {:.3f}, auc = {:.2f}'.format(acc_test, roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(np.array(x_test), np.array(y_test), verbose=0)\n",
    "print('Test log loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('loss, per batch')\n",
    "plt.plot(bl.get_values('loss',1), 'b-', label='train');\n",
    "plt.plot(bl.get_values('val_loss',1), 'r-', label='test');\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('accuracy, per batch')\n",
    "plt.plot(bl.get_values('acc',1), 'b-', label='train');\n",
    "plt.plot(bl.get_values('val_acc',1), 'r-', label='test');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict_on_batch(np.array(x_train))[:,0]\n",
    "y_test_pred = model.predict_on_batch(np.array(x_test))[:,0]\n",
    "\n",
    "fig,ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "plot_cm(ax[0], y_train, y_train_pred, [0,1], 'Confusion matrix (TRAIN)')\n",
    "plot_cm(ax[1], y_test, y_test_pred, [0,1], 'Confusion matrix (TEST)')\n",
    "\n",
    "plot_auc(ax[2], y_train, y_train_pred, y_test, y_test_pred)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "'''\n",
    "# predict probabilities for test set\n",
    "y_pred_probs = model.predict(x_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "y_pred_classes = model.predict_classes(x_test, verbose=0)\n",
    "\n",
    "# reduce to 1d array\n",
    "y_pred_probs = y_pred_probs[:, 0]\n",
    "y_pred_classes = y_pred_classes[:, 0]\n",
    "\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_pred_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "print(matrix)\n",
    "'''\n",
    "# predict probabilities for test set\n",
    "y_pred_probs = model.predict(x_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "y_pred_classes = model.predict_classes(x_test, verbose=0)\n",
    "\n",
    "# reduce to 1d array\n",
    "y_pred_probs = y_pred_probs[:, 0]\n",
    "y_pred_classes = y_pred_classes[:, 0]\n",
    "\n",
    "# evaluate the model performance\n",
    "metrics.loc['accuracy', 'NeuralNet'] = accuracy_score(y_test, y_pred_classes)\n",
    "metrics.loc['precision', 'NeuralNet'] = precision_score(y_test, y_pred_classes)\n",
    "metrics.loc['recall', 'NeuralNet'] = recall_score(y_test, y_pred_classes)\n",
    "\n",
    "# construct the confusion matrix\n",
    "CM = confusion_matrix(y_test, y_pred_classes)\n",
    "c_matrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "metrics.plot(kind='barh', ax=ax)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust precision and recall by modifying the classification thresholds\n",
    "# predict_proba gives you the probabilities for the target (0 and 1 in your case) in array form\n",
    "precision_nb, recall_nb, thresholds_nb = precision_recall_curve(y_true=y_test, probas_pred=nb_classifier.predict_proba(x_test)[:,1])\n",
    "\n",
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve(y_true=y_test, probas_pred=log_reg.predict_proba(x_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(precision_nb, recall_nb, label='NaiveBayes')\n",
    "ax.plot(precision_lr, recall_lr, label='LogisticReg')\n",
    "ax.set_xlabel('Precision')\n",
    "ax.set_ylabel('Recall')\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.hlines(y=0.5, xmin=0, xmax=1, color='red')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "# Logistic regression is better than Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for modified Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "print(thresholds_lr)\n",
    "print(precision_lr)\n",
    "ax.plot(thresholds_lr, precision_lr[1:], label='Precision')\n",
    "ax.plot(thresholds_lr, recall_lr[1:], label='Recall')\n",
    "ax.set_xlabel('Classfication Threshold')\n",
    "ax.set_ylabel('Precision, Recall')\n",
    "ax.set_title('Logistic Regression Classifier: Precision-Recall')\n",
    "ax.hlines(y=0.6, xmin=0, xmax=1, color='red')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with threshold of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = log_reg.predict_proba(x_test)[:,1]\n",
    "y_predicted = (y_pred_proba >= 0.2).astype('int')\n",
    "# adjust the original classification threshold from 0.5 to 0.2\n",
    "\n",
    "# confusion matrix\n",
    "CM = confusion_matrix(y_pred=y_predicted, y_true=y_test)\n",
    "print(\"Recall: \", 100*recall_score(y_pred=y_predicted, y_true=y_test))\n",
    "print(\"Precision: \", 100*precision_score(y_pred=y_predicted, y_true=y_test))\n",
    "c_matrix(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Predictive Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_default(new_data):\n",
    "    '''\n",
    "    #print(new_data)\n",
    "    #print(new_data.shape)\n",
    "    # The criterion to satisfy for providing the new shape is that 'The new shape should be compatible with the original shape'\n",
    "    # https://stackoverflow.com/questions/18691084/what-does-1-mean-in-numpy-reshape\n",
    "    '''\n",
    "    data = new_data.values.reshape(1, -1)\n",
    "    data = robust_scaler.transform(data)\n",
    "    prob = log_reg.predict_proba(data)[0][1]\n",
    "    if prob >= 0.2:\n",
    "        return \"Will default\"\n",
    "    else:\n",
    "        return \"Will pay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay = df[df['default']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "new_customer = OrderedDict([\n",
    "    ('LIMIT_BAL', 4000), ('AGE', 50), ('BILL_AMT1', 500),\n",
    "    ('BILL_AMT2', 35509), ('BILL_AMT3', 689), ('BILL_AMT4', 0),\n",
    "    ('BILL_AMT5', 0), ('BILL_AMT6', 0), ('PAY_AMT1', 0),\n",
    "    ('PAY_AMT2', 35509), ('PAY_AMT3', 0), ('PAY_AMT4', 0),\n",
    "    ('PAY_AMT5', 0), ('PAY_AMT6', 0), ('male', 1), ('grad_school', 0),\n",
    "    ('university', 1), ('high_school', 0), ('married', 1), ('single', 0), ('pay_0', -1),\n",
    "    ('pay_2', -1), ('pay_3', -1), ('pay_4', 0), ('pay_5', -1), ('pay_6', 0),\n",
    "])\n",
    "\n",
    "new_customer = pd.Series(new_customer)\n",
    "predict_default(new_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for x in negative.index[0:100]:\n",
    "    print(predict_default(negative.loc[x].drop('default')))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
